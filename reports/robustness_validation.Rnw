

<<load_data_from_files>>=
load("esets.not.rescaled.classified.RData")
load("esets.not.rescaled.classified.concordant.RData")

# These are the dataset names with TCGA RNASeq removed
dataset.names <- names(esets.not.rescaled.classified)

clustering.subtypes <- list()

for(dirname in c("konecny_nmf_4", "tcga_nmf_4", "tothill_kmeans_4")) {
  cluster.classes <- list()
  for(current.eset.name in dataset.names) {
    cluster.classes[[current.eset.name]] <- list()
    filenames <- Sys.glob(paste0("apr12clusters/", dirname, "/", current.eset.name, "_*_classes.txt"))
    for(filename in filenames) {
      cluster.classes[[current.eset.name]][[length(cluster.classes[[current.eset.name]])+1]] <- scan(filename, what=character(0))
    }
  }
  clustering.subtypes[[dirname]] <- cluster.classes
}


classifier.subtypes <- lapply(c("Konecny.subtypes", "Verhaak.subtypes", "Helland.subtypes"), function(subtype.colname) {
  subtype.classes <- list()
  for(current.eset.name in dataset.names) {
    subtype.classes[[current.eset.name]] <- as.character(pData(esets.not.rescaled.classified[[current.eset.name]])[,subtype.colname])
  }
  return(subtype.classes)
})

names(classifier.subtypes) <- c("Konecny", "Verhaak", "Helland")

clustering.subtypes.concordant <- list()

for(dirname in c("konecny_nmf_4", "tcga_nmf_4", "tothill_kmeans_4")) {
  cluster.classes <- list()
  for(current.eset.name in dataset.names) {
    cluster.classes[[current.eset.name]] <- list()
    filenames <- Sys.glob(paste0("may3clusters_concordant/", dirname, "/", current.eset.name, "_*_classes.txt"))
    for(filename in filenames) {
      cluster.classes[[current.eset.name]][[length(cluster.classes[[current.eset.name]])+1]] <- scan(filename, what=character(0))
    }
  }
  clustering.subtypes.concordant[[dirname]] <- cluster.classes
}


classifier.subtypes.concordant <- lapply(c("Konecny.subtypes", "Verhaak.subtypes", "Helland.subtypes"), function(subtype.colname) {
  subtype.classes <- list()
  for(current.eset.name in dataset.names) {
    subtype.classes[[current.eset.name]] <- as.character(pData(esets.not.rescaled.classified.concordant[[current.eset.name]])[,subtype.colname])
  }
  return(subtype.classes)
})

names(classifier.subtypes.concordant) <- c("Konecny", "Verhaak", "Helland")

# Remove clustering/classification subtypes performed on the original dataset
clustering.subtypes$tcga_nmf_4$TCGA <- NULL
clustering.subtypes$tothill_kmeans_4$GSE9891 <- NULL
classifier.subtypes$Verhaak$TCGA <- NULL
classifier.subtypes$Helland$GSE9891 <- NULL

clustering.subtypes.concordant$tcga_nmf_4$TCGA <- NULL
clustering.subtypes.concordant$tothill_kmeans_4$GSE9891 <- NULL
classifier.subtypes.concordant$Verhaak$TCGA <- NULL
classifier.subtypes.concordant$Helland$GSE9891 <- NULL

@


An important trait of a robust molecular subtyping scheme is that it should be present and discoverable in multiple datasets. We performed de novo clustering in \Sexpr{length(dataset.names)} independent ovarian datasets using the authors' original gene lists and clustering method. We compared these de novo cluster groupings to the labels from our implemented classifiers using the prediction strength statistic of Tibshirani and Walther, 2005.


In order to permit comparability between subtyping schemes, all datasets were filtered to patients with high-grade serous ovarian carcinomas.
%I performed clustering on 11 datasets from MetaGxOvarian:
%\Sexpr{dataset.names}

%Clustering was performed using a grid of 126 algorithm configurations:

%\vspace{10pt}

%\begin{tabular}{ | p{3cm} | p{3cm} |p{0.4cm} |} 
%\hline Algorithm & Gene Set & k \\ \hline 
%Consensus k-means NMF & TCGA gene set Tothill gene set Top 1000 by MAD Top 1500 by MAD Top 2000 by MAD Top 2500 by MAD Top 3000 by MAD & 2 3 4 5 6 7 8 9 10
%\\ \hline \end{tabular}
<<TCGA_pred_str, cache=TRUE>>=
tcga.ps.vals <- sapply(1:length(classifier.subtypes$Verhaak), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes$Verhaak[[x]], clustering.subtypes$tcga_nmf_4[[x]][[y]])$ps))
colnames(tcga.ps.vals) <- names(classifier.subtypes$Verhaak)

tcga.ps.vals.concordant <- sapply(1:length(classifier.subtypes.concordant$Verhaak), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes.concordant$Verhaak[[x]], clustering.subtypes.concordant$tcga_nmf_4[[x]][[y]])$ps))
colnames(tcga.ps.vals.concordant) <- names(classifier.subtypes.concordant$Verhaak)

tcga.ordered.classes <- c("IMR", "DIF", "PRO", "MES")

@

<<tcga_pred_str_margin_trend_computation>>=
tcga.pred.str.trend <- lapply(names(classifier.subtypes$Verhaak), function(dataset.name) {
  if(length(classifier.subtypes$Verhaak[[dataset.name]]) < 100) {
    return(NA)
  }
  
  # Get the index of the median clustering (since there is an even number of clusterings, use the median of the first 99)
  median.clustering.index <- which(tcga.ps.vals[,dataset.name] == median(tcga.ps.vals[,dataset.name][-100]))[1]
  xvals <- seq(length(classifier.subtypes$Verhaak[[dataset.name]]), 50, by = -25)
  ps.vals <- sapply(xvals, function(x) {
    # calculate Prediction Strength; use the top x samples (by margin)
    margin.vals <- esets.not.rescaled.classified[[dataset.name]]$Verhaak.margins
    samples.to.keep <- margin.vals >= sort(margin.vals)[length(margin.vals)-x+1]
    if(sum(samples.to.keep) <= 1) {
      return(NA)
    }
    current.ps <- ps.cluster(classifier.subtypes$Verhaak[[dataset.name]][samples.to.keep], clustering.subtypes$tcga_nmf_4[[dataset.name]][[median.clustering.index]][samples.to.keep])$ps
    return(current.ps)
  })

  out.df <- data.frame(dataset.size=xvals, prediction.strength=ps.vals)
  return(out.df)
})

names(tcga.pred.str.trend) <- names(classifier.subtypes$Verhaak)

tcga.pred.str.trend <- tcga.pred.str.trend[!is.na(tcga.pred.str.trend)]

for(dataset.name in names(tcga.pred.str.trend)) {
  tcga.pred.str.trend[[dataset.name]]$dataset.name <- dataset.name
}
tcga.pred.str.trend.combined <- Reduce(function(...) merge(..., all=TRUE), tcga.pred.str.trend)

tcga.mean.ps.df <- data.frame(dataset.size=unique(tcga.pred.str.trend.combined$dataset.size))
tcga.mean.ps.df$prediction.strength <- sapply(tcga.mean.ps.df$dataset.size, function(dataset.size) mean(tcga.pred.str.trend.combined$prediction.strength[tcga.pred.str.trend.combined$dataset.size==dataset.size]))
@



<<tcga_pred_str_margin_trend_average, eval=FALSE>>=
ggplot(tcga.mean.ps.df, aes(y=prediction.strength, x = dataset.size)) + geom_point(size=4) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: TCGA/Verhaak") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse()
@

<<Tothill_pred_str, cache=TRUE>>=
tothill.ps.vals <- sapply(1:length(classifier.subtypes$Helland), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes$Helland[[x]], clustering.subtypes$tothill_kmeans_4[[x]][[y]])$ps))
colnames(tothill.ps.vals) <- names(classifier.subtypes$Helland)

tothill.ps.vals.concordant <- sapply(1:length(classifier.subtypes.concordant$Helland), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes.concordant$Helland[[x]], clustering.subtypes.concordant$tothill_kmeans_4[[x]][[y]])$ps))
colnames(tothill.ps.vals.concordant) <- names(classifier.subtypes.concordant$Helland)

tothill.ordered.classes <- c("C2", "C4", "C5", "C1")
@

<<tothill_pred_str_margin_trend_computation>>=
tothill.pred.str.trend <- lapply(names(classifier.subtypes$Helland), function(dataset.name) {
  if(length(classifier.subtypes$Helland[[dataset.name]]) < 100) {
    return(NA)
  }
  
  # Get the index of the median clustering (since there is an even number of clusterings, use the median of the first 99)
  median.clustering.index <- which(tothill.ps.vals[,dataset.name] == median(tothill.ps.vals[,dataset.name][-100]))[1]
  xvals <- seq(length(classifier.subtypes$Helland[[dataset.name]]), 50, by=-25)
  ps.vals <- sapply(xvals, function(x) {
    # calculate Prediction Strength; use the top x samples (by margin)
    margin.vals <- esets.not.rescaled.classified[[dataset.name]]$Helland.margins
    samples.to.keep <- margin.vals >= sort(margin.vals)[length(margin.vals)-x+1]
    current.ps <- ps.cluster(classifier.subtypes$Helland[[dataset.name]][samples.to.keep], clustering.subtypes$tothill_kmeans_4[[dataset.name]][[median.clustering.index]][samples.to.keep])$ps
    return(current.ps)
  })

  out.df <- data.frame(dataset.size=xvals, prediction.strength=ps.vals)
  return(out.df)
})

names(tothill.pred.str.trend) <- names(classifier.subtypes$Helland)

tothill.pred.str.trend <- tothill.pred.str.trend[!is.na(tothill.pred.str.trend)]

for(dataset.name in names(tothill.pred.str.trend)) {
  tothill.pred.str.trend[[dataset.name]]$dataset.name <- dataset.name
}

tothill.pred.str.trend.combined <- Reduce(function(...) merge(..., all=TRUE), tothill.pred.str.trend)

tothill.mean.ps.df <- data.frame(dataset.size=unique(tothill.pred.str.trend.combined$dataset.size))
tothill.mean.ps.df$prediction.strength <- sapply(tothill.mean.ps.df$dataset.size, function(dataset.size) mean(tothill.pred.str.trend.combined$prediction.strength[tothill.pred.str.trend.combined$dataset.size==dataset.size]))
@

<<tothill_pred_str_margin_trend_average, eval=FALSE>>=
ggplot(tothill.mean.ps.df, aes(y=prediction.strength, x = dataset.size)) + geom_point(size=4) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: Tothill/Helland") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse()
@

<<tothill_pred_str_margin_trend_tcga, eval=FALSE>>=
ggplot(tothill.pred.str.trend.combined[tothill.pred.str.trend.combined$dataset.name=="TCGA",], aes(y=prediction.strength, x = dataset.size, colour = dataset.name)) + geom_point(size=2) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse()
@

<<Konecny_pred_str, cache=TRUE>>=
konecny.ps.vals <- sapply(1:length(classifier.subtypes$Konecny), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes$Konecny[[x]], clustering.subtypes$konecny_nmf_4[[x]][[y]])$ps))
colnames(konecny.ps.vals) <- names(classifier.subtypes$Konecny)

konecny.ps.vals.concordant <- sapply(1:length(classifier.subtypes.concordant$Konecny), function(x) sapply(1:100, function(y) ps.cluster(classifier.subtypes.concordant$Konecny[[x]], clustering.subtypes.concordant$konecny_nmf_4[[x]][[y]])$ps))
colnames(konecny.ps.vals.concordant) <- names(classifier.subtypes.concordant$Konecny)

konecny.ordered.classes <- c("C1_immL", "C2_diffL", "C3_profL", "C4_mescL")
@

<<konecny_pred_str_margin_trend_computation>>=
konecny.pred.str.trend <- lapply(names(classifier.subtypes$Konecny), function(dataset.name) {
  if(length(classifier.subtypes$Konecny[[dataset.name]]) < 100) {
    return(NA)
  }
  
  # Get the index of the median clustering (since there is an even number of clusterings, use the median of the first 99)
  median.clustering.index <- which(konecny.ps.vals[,dataset.name] == median(konecny.ps.vals[,dataset.name][-100]))[1]
  
  xvals <- seq(length(classifier.subtypes$Konecny[[dataset.name]]), 50, by=-25)
  
  ps.vals <- sapply(xvals, function(x) {
    # calculate Prediction Strength; use the top x samples (by margin)
    margin.vals <- esets.not.rescaled.classified[[dataset.name]]$Konecny.margins
    samples.to.keep <- margin.vals >= sort(margin.vals)[length(margin.vals)-x+1]
    current.ps <- ps.cluster(classifier.subtypes$Konecny[[dataset.name]][samples.to.keep], clustering.subtypes$konecny_nmf_4[[dataset.name]][[median.clustering.index]][samples.to.keep])$ps
    return(current.ps)
  })

  out.df <- data.frame(dataset.size=xvals, prediction.strength=ps.vals)
  return(out.df)
})

names(konecny.pred.str.trend) <- names(classifier.subtypes$Konecny)

konecny.pred.str.trend <- konecny.pred.str.trend[!is.na(konecny.pred.str.trend)]

for(dataset.name in names(konecny.pred.str.trend)) {
  konecny.pred.str.trend[[dataset.name]]$dataset.name <- dataset.name
}

konecny.pred.str.trend.combined <- Reduce(function(...) merge(..., all=TRUE), konecny.pred.str.trend)

konecny.mean.ps.df <- data.frame(dataset.size=unique(konecny.pred.str.trend.combined$dataset.size))
konecny.mean.ps.df$prediction.strength <- sapply(konecny.mean.ps.df$dataset.size, function(dataset.size) mean(konecny.pred.str.trend.combined$prediction.strength[konecny.pred.str.trend.combined$dataset.size==dataset.size]))
@

<<konecny_pred_str_margin_trend_average, eval=FALSE>>=
ggplot(konecny.mean.ps.df, aes(y=prediction.strength, x = dataset.size)) + geom_point(size=4) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: konecny/Konecny") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse()
@

<<konecny_pred_str_margin_trend_tcga, eval=FALSE>>=
ggplot(konecny.pred.str.trend.combined[konecny.pred.str.trend.combined$dataset.name=="TCGA",], aes(y=prediction.strength, x = dataset.size, colour = dataset.name)) + geom_point(size=2) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse()
@

Each dataset was clustered according to our implementation of the clustering algorithms and gene sets of Konecny, TCGA, and Tothill. Each dataset was also classified using our implementation of the corresponding classification algorithms of Konecny, TCGA/Verhaak, and Tothill/Helland. This produced two sets of subtype labels for each validation dataset, from which we computed prediction strength.

We performed each clustering algorithm 100 times for each dataset, producing 100 prediction strength estimates per dataset. In the boxplot below, each data point represents the mean estimated prediction strength for a dataset under a given subtyping clustering/classification scheme.

<<ps_combined_boxplot, out.width="0.7\\textwidth">>=

set.seed(900)
combined.ps <- lapply(list(Tothill=tothill.ps.vals, TCGA=tcga.ps.vals, Konecny=konecny.ps.vals), function(x) data.frame(dataset=colnames(x), pred.strength=apply(x, 2, mean)))
combined.ps.m <- melt(combined.ps)
combined.ps.m$variable <- NULL

ggplot(combined.ps.m, aes(x=L1, y=value, fill="red")) + stat_boxplot(geom='errorbar') + geom_boxplot(color="black", outlier.shape=NA) + geom_jitter(position=position_jitter(0.1), cex=0.5) + scale_y_continuous(limits=c(0,1), breaks=seq(0,1,0.2)) + theme_bw() + ggtitle("Robustness of Molecular Subtyping Schemes") + xlab("") + ylab("Prediction Strength") + xlab("Subtyping Scheme") + theme(plot.title=element_text(size=20, vjust=2)) + coord_cartesian(ylim = c(0, 1)) + theme(legend.position='none')
@

Next, we 

<<ps_paired_boxplots, fig.width=10, out.width="0.85\\textwidth">>=
set.seed(900)
combined.ps.concordant <- lapply(list(Tothill=tothill.ps.vals.concordant, TCGA=tcga.ps.vals.concordant, Konecny=konecny.ps.vals.concordant), function(x) data.frame(dataset=colnames(x), pred.strength=apply(x, 2, mean)))
combined.ps.concordant.m <- melt(combined.ps.concordant)
combined.ps.concordant.m$variable <- NULL

combined.ps.concordant.m$Data <- "Concordant"
combined.ps.m$Data <- "All"

pred.str.df <- rbind(combined.ps.m, combined.ps.concordant.m)

colnames(pred.str.df)[2:3] <- c("pred.strength", "Method")

#ggplot(pred.str.df, aes(x=interaction(Data, Method), y=pred.strength)) + geom_boxplot(aes(fill=Data), outlier.size=0) + geom_line(aes(group=interaction(dataset, Method)), alpha=0.2, cex=0.5) + geom_jitter(position=position_jitter(0), cex=0.3) + theme_bw() + ggtitle("Robustness: All Data and Concordant Cases") + xlab("Subtyping Scheme") + ylab("Prediction Strength") + theme(plot.title=element_text(size=20, vjust=2)) + coord_cartesian(ylim = c(0, 1))  + scale_x_discrete(labels=c("                        Konecny", "", "                        TCGA", "", "                     Tothill", ""))

ggplot(pred.str.df, aes(x=interaction(Data, Method), y=pred.strength)) + stat_boxplot(geom='errorbar') + geom_boxplot(aes(fill=Data), outlier.shape=NA) + geom_jitter(position=position_jitter(0.1), cex=0.5) + theme_bw() + ggtitle("Robustness: All Data and Concordant Cases") + xlab("Subtyping Scheme") + ylab("Prediction Strength") + theme(plot.title=element_text(size=20, vjust=2)) + coord_cartesian(ylim = c(0, 1))  + scale_x_discrete(labels=c("                        Konecny", "", "                        TCGA", "", "                     Tothill", ""))

@

\pagebreak
Next, we computed Prediction Strength using various dataset sizes. For each classifier, we included validation datasets with greater than 100 late-stage high-grade serous patients. We excluded the dataset used to train the original classifier, and restricted margin cutoff values to include at least 50 patients. Using classifier margin values to define cutoffs, we computed Prediction Strength for subsets of each dataset. From the 100 cluster runs, we used the run that produced the median prediction strength for each full dataset.
\subsection{TCGA/Verhaak}
<<tcga_pred_str_margin_trend>>=

ggplot(tcga.pred.str.trend.combined, aes(y=prediction.strength, x = dataset.size, colour = dataset.name)) + geom_point(size=1) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: TCGA/Verhaak") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse() + geom_line()
@
\pagebreak

\subsection{Tothill/Helland}
For the clustering algorithm and classifier described in Tothill (2008) and Helland (2011), we observed an increase in robustness of subtypes in the TCGA dataset.
<<tothill_pred_str_margin_trend>>=

ggplot(tothill.pred.str.trend.combined, aes(y=prediction.strength, x = dataset.size, colour = dataset.name)) + geom_point(size=1) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: Tothill/Helland") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse() + geom_line()
@
\pagebreak
\subsection{Konecny}
For the clustering algorithm and classifier described in Konecny (2014), we observed an increase in robustness of subtypes in the TCGA dataset.
<<konecny_pred_str_margin_trend>>=

ggplot(konecny.pred.str.trend.combined, aes(y=prediction.strength, x = dataset.size, colour = dataset.name)) + geom_point(size=1) + theme_bw() + xlab("Dataset Size") + ylab("Prediction Strength: Konecny") + ylim(0, 1) + ggtitle("Prediction Strength") + scale_x_reverse() + geom_line()
@
